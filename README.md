The inspiration behind creating a "SOUNDMATE : Smart Device for the Hearing Impaired" concept came from witnessing one of our team membersâ€™ grandfather face challenges with hearing due to age. Observing his struggles with daily communication and reliance on others for safety motivated us to develop technology that could support greater independence for those with hearing impairments. While the smart watch itself remains part of our future development scope, we focused on building the foundational components, including an audio classification model and speech-to-text functionality. These elements will eventually integrate into a wearable device that can detect critical sounds, such as car horns and sirens, and alert the user through vibrations and visual notifications on a mobile app.

The Smart Wearable for the Hearing Impaired is an innovative device that will be designed to enhance safety and situational awareness for individuals with hearing impairments. It will detect and classify important environmental sounds, such as car horns and sirens, alerting users through vibrations when these critical sounds are identified. The device will also provide real-time speech-to-text translations via a mobile app, ensuring users remain aware of their surroundings. Additionally, it will indicate the relative direction of detected sounds, helping users navigate their environment more effectively. The wearable will notify users when their registered name is called out, ensuring they never miss important interactions. Visual representations of audio classifications will be displayed on the mobile interface, providing an intuitive and interactive way for users to understand their environment.

We designed the audio classification model. The input (which can be the recording audio file of surrounding noise) is processed by calculating Mel Frequency Cepstral Coefficients (MFCC) for feature extraction and classification. Our model can identify important sounds and trigger notifications, enabling users to recognize specific alerts. Additionally, we implemented a speech-to-text feature on a mobile app, allowing users to receive real-time visual representations of sounds, further supporting communication and awareness.
